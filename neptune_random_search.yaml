project: TDAT

name: talking data
tags: [solution-1]

metric:
  channel: 'ROC_AUC'
  goal: maximize

# Comment out if not in Cloud Environment
pip-requirements-file: requirements.txt

exclude:
  - output
  - imgs
  - neptune.log
  - offline_job.log
  - .git
  - .idea
  - .ipynb_checkpoints
  - notebooks

parameters:
# Data
  raw_train_filepath: /public/talking_data/data/train.csv
  train_chunks_dir: /public/talking_data/files/train_chunks
  test_chunks_dir: /public/talking_data/files/test_chunks
  test_filepath: /public/talking_data/data/test.csv
  test_suplement_filepath: /public/talking_data/data/test_supplement.csv
  experiment_dir: /ouptut/solution_week_2
  train_days_hours: '{7: [17,18,19,20,21,22,23], 8: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}'
  valid_days_hours: '{8: [17,18,19,20,21,22,23], 9: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}'
  test_days_hours: '{9: [17,18,19,20,21,22,23], 10: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}'
  submission_hours: '[4,5,9,10,13,14]'

# Execution
  overwrite: 1
  num_workers: 10
  verbose: 1

# Preprocessing
  target_encoder__n_splits: 10

# Light GBM
  lgbm_random_search_runs: 100
  lgbm__boosting_type: gbdt
  lgbm__objective: binary
  lgbm__metric: auc
  lgbm__number_boosting_rounds: 100
  lgbm__early_stopping_rounds: 10
  lgbm__learning_rate: '[0.01, 0.3, "log-uniform"]'
  lgbm__num_leaves: '[25, 250]'
  lgbm__max_depth: '[3,5,7,9,12,15,17,25, "list"]'
  lgbm__min_child_samples: '[0, 50]'
  lgbm__max_bin: '[50, 500]'
  lgbm__subsample: '[0.6,0.7,0.8,0.9,1.0, "list"]'
  lgbm__subsample_freq: '[0, 4]'
  lgbm__colsample_bytree: '[0.6,0.7,0.8,0.9,1.0, "list"]'
  lgbm__min_child_weight: '[1,3,5,7,"list"]'
  lgbm__reg_lambda: '[1e-3, 1.0, "log-uniform"]'
  lgbm__reg_alpha: 0
  lgbm__scale_pos_weight: '[10, 1000, "log-uniform"]'

# XGBoost
  xgboost_random_search_runs: 100
  xgboost__booster: gbtree
  xgboost__objective: 'binary:logistic'
  xgboost__eval_metric: 'auc'
  xgboost__number_boosting_rounds: 100
  xgboost__early_stopping_rounds: 10
  xgboost__maximize: True
  xgboost__learning_rate: '[0.01, 0.3, "log-uniform"]'
  xgboost__max_depth: '[3,5,7,9,12,15,17,25, "list"]'
  xgboost__min_child_weight: '[1,3,5,7,"list"]'
  xgboost__gamma: '[0.05,0.1,0.3,0.5,0.7,0.9,1.0, "list"]'
  xgboost__subsample: '[0.6,0.7,0.8,0.9,1.0, "list"]'
  xgboost__colsample_bytree: '[0.6,0.7,0.8,0.9,1.0, "list"]'
  xgboost__reg_lambda:  '[1e-3, 1.0, "log-uniform"]'
  xgboost__reg_alpha: 0.0
  xgboost__scale_pos_weight: '[10, 1000, "log-uniform"]'

# Random Forest
  random_forest_random_search_runs: 100
  random_forest__n_estimators: 500
  random_forest__max_depth: '[5,8,15,25,30,None, "list"]'
  random_forest__min_samples_split: '[1,2,5,10,15,100, "list"]'
  random_forest__min_samples_leaf: '[1,2,5,10, "list"]'
  random_forest__max_features: '["log2","sqrt","auto", "list"]'
  random_forest__class_weight: '{0:1, 1:200}'